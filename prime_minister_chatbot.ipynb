{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "!pip install langchain\n!pip install openai==0.28.1\n!pip install chromadb==0.4.15\n!pip install tiktoken",
      "metadata": {
        "id": "wKxtrDBXviRN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import requests\nfrom bs4 import BeautifulSoup\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import Chroma\nfrom langchain.document_loaders import TextLoader\n\n# URL of the Wikipedia page to scrape\nurl = 'https://en.wikipedia.org/wiki/Prime_Minister_of_the_United_Kingdom'\n\n# Send a GET request to the URL\nresponse = requests.get(url)\n\n# Parse the HTML content using BeautifulSoup\nsoup = BeautifulSoup(response.content, 'html.parser')\n\n# Find all the text on the page\ntext = soup.get_text()\ntext = text.replace('\\n', '')\n\n# Open a new file called 'output.txt' in write mode and store the file object in a variable\nwith open('output.txt', 'w', encoding='utf-8') as file:\n    # Write the string to the file\n    file.write(text)",
      "metadata": {
        "id": "pzhuY_utvRdz"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "from langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# load the document\nwith open('./output.txt', encoding='utf-8') as f:\n    text = f.read()\n\n# define the text splitter\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 500,\n    chunk_overlap  = 100,\n    length_function = len,\n)\n\ntexts = text_splitter.create_documents([text])",
      "metadata": {
        "id": "JLEFXcwIvcHc"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "import os\nos.environ[\"OPENAI_API_KEY\"] = \"testapikey\"\n\n# define the embeddings model\nembeddings = OpenAIEmbeddings()\n\n# use the text chunks and the embeddings model to fill our vector store\ndb = Chroma.from_documents(texts, embeddings)",
      "metadata": {
        "id": "NFBZdF2nvtqN"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "from langchain.llms import OpenAI\nfrom langchain import PromptTemplate\n\nllm = OpenAI(model_name=\"text-davinci-003\", temperature=0.7)\n\n# Test current llm set-up without adding RAG (Retrieval Augmentation Generation)\nprint(llm(\"Who is the current Prime Minister of the United Kingdom?\"))",
      "metadata": {
        "id": "tW74xpmsQ_4y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# define the prompt template\ntemplate = \"\"\"\nYou are a chat bot who loves to help people! Given the following context sections, answer the\nquestion using only the given context. If you are unsure and the answer is not\nexplicitly written in the documentation, say \"Sorry, I don't know how to help with that.\" The current year is 2023.\n\nContext sections:\n{context}\n\nQuestion:\n{users_question}\n\nAnswer:\n\"\"\"\n\nprompt = PromptTemplate(template=template, input_variables=[\"context\", \"users_question\"])",
      "metadata": {
        "id": "sYfYQ9Mrv_6R"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": "!pip install pyngrok==4.1.1\n!pip install flask_ngrok\n!ngrok authtoken 'testauthtoken'",
      "metadata": {
        "id": "vl7OQW4NQSzH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from flask import Flask, render_template, request\nfrom flask_ngrok import run_with_ngrok\n\napp = Flask(__name__)\nrun_with_ngrok(app)  # Start ngrok when app is run\n\nclass Chatbot():\n  def __init__(self, llm_model, prompt_template, vector_store):\n        self.llm = llm_model\n        self.prompt = prompt_template\n        self.vector_store = vector_store\n\n  def generate_response(self, user_input):\n        if user_input.lower() == 'exit':\n            return \"Exiting the chatbot. Goodbye!\"\n\n        users_question = user_input\n\n        results = self.vector_store.similarity_search(query=users_question, n_results=5)\n\n        # Prepare prompt with user's question and retrieved context\n        prompt_text = self.prompt.format(context=results, users_question=users_question)\n\n        # Ask the defined language model based on the context and user's question\n        response = self.llm(prompt_text)\n\n        return response\n\n#Define a route for the home page\n@app.route(\"/\")\ndef home():\n    return  render_template(\"index.html\")\n\n#Define a route for handling user input and getting the bot's response\n@app.route(\"/get\")\ndef get_bot_response():\n    chatbot_object = Chatbot(llm_model=llm, prompt_template=prompt, vector_store=db)\n    user_input = request.args.get('msg')\n    return str(chatbot_object.generate_response(user_input))\n\n#Start the Flask application if this script is executed\nif __name__ == \"__main__\":\n    app.run() #debug=True",
      "metadata": {
        "id": "sHBIMGBLQTJf"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}